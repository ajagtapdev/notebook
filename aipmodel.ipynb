{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install ultralytics\n",
    "%pip install ipywidgets\n",
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# load the yolov8 model for object detection\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "def process_frame(frame, width, height, person_tracks, vehicle_tracks):\n",
    "    # run object detection on the frame\n",
    "    results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")\n",
    "    if results[0].boxes is not None:\n",
    "        # get bounding boxes, class ids, and track ids\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "        track_ids = results[0].boxes.id.cpu().numpy() if hasattr(results[0].boxes, 'id') else np.array([])\n",
    "\n",
    "        # loop through detected objects\n",
    "        for box, class_id, track_id in zip(boxes, class_ids, track_ids):\n",
    "            # calculate center of the bounding box\n",
    "            center_x = (box[0] + box[2]) / 2 / width\n",
    "            center_y = (box[1] + box[3]) / 2 / height\n",
    "\n",
    "            # draw the bounding box and label\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            label = f\"ID {int(track_id)}\"\n",
    "            color = (0, 255, 0) if class_id == 0 else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # save the tracking points for each class\n",
    "            if class_id == 0:\n",
    "                person_tracks.setdefault(track_id, []).append((center_x, center_y))\n",
    "            elif class_id in [2, 3, 5, 7]:\n",
    "                vehicle_tracks.setdefault(track_id, []).append((center_x, center_y))\n",
    "    return frame\n",
    "\n",
    "def process_video_and_generate_output(video_path, output_video_path, animation_output_path, final_graph_path):\n",
    "    # open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise FileNotFoundError(f\"Could not open video file: {video_path}\")\n",
    "\n",
    "    # get video properties like width, height, and fps\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # initialize the video writer for saving the output video\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
    "    person_tracks, vehicle_tracks = {}, {}\n",
    "\n",
    "    # use thread pool to process frames concurrently\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_frames = []\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            future = executor.submit(process_frame, frame, width, height, person_tracks, vehicle_tracks)\n",
    "            future_frames.append(future)\n",
    "\n",
    "        # write the processed frames to the output video\n",
    "        for future in future_frames:\n",
    "            frame = future.result()\n",
    "            out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # create an animated plot of the tracks\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    def update(frame_idx):\n",
    "        ax.clear()\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(True)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "        # plot tracks up to the current frame\n",
    "        for points in person_tracks.values():\n",
    "            if frame_idx < len(points):\n",
    "                points_arr = np.array(points)\n",
    "                ax.plot(points_arr[:frame_idx + 1, 0], points_arr[:frame_idx + 1, 1], 'b-', alpha=0.7)\n",
    "        for points in vehicle_tracks.values():\n",
    "            if frame_idx < len(points):\n",
    "                points_arr = np.array(points)\n",
    "                ax.plot(points_arr[:frame_idx + 1, 0], points_arr[:frame_idx + 1, 1], 'r-', alpha=0.7)\n",
    "\n",
    "    # save the animation as a gif\n",
    "    anim = FuncAnimation(fig, update, frames=max(len(points) for points in list(person_tracks.values()) + list(vehicle_tracks.values())), interval=1000 // fps)\n",
    "    anim.save(animation_output_path, writer=PillowWriter(fps=fps))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # plot the final tracks and save as an image\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    # plot the complete tracks for persons and vehicles\n",
    "    for points in person_tracks.values():\n",
    "        points_arr = np.array(points)\n",
    "        ax.plot(points_arr[:, 0], points_arr[:, 1], 'b-', alpha=0.7)\n",
    "    for points in vehicle_tracks.values():\n",
    "        points_arr = np.array(points)\n",
    "        ax.plot(points_arr[:, 0], points_arr[:, 1], 'r-', alpha=0.7)\n",
    "\n",
    "    # save the final graph\n",
    "    plt.savefig(final_graph_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "# example usage with paths to input and output files\n",
    "video_path = r\"C:\\Users\\aarus\\Downloads\\example3.mp4\"\n",
    "output_video_path = r\"C:\\Users\\aarus\\Downloads\\example3output.mp4\"\n",
    "animation_output_path = r\"C:\\Users\\aarus\\Downloads\\example3gif.gif\"\n",
    "final_graph_path = r\"C:\\Users\\aarus\\Downloads\\example3graph.jpg\"\n",
    "\n",
    "process_video_and_generate_output(video_path, output_video_path, animation_output_path, final_graph_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
